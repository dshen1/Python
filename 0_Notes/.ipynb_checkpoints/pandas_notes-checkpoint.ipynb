{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Notes for Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## import all libs \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## some sample data \n",
    "\n",
    "df = pd.read_csv('data/CDIS.csv',encoding = 'iso-8859-1')\n",
    "var_names = df.columns.values\n",
    "droplist = [x for x in var_names if x.startswith(\"Status\")]        # pick out all columns with Status\n",
    "df.drop(droplist,axis=1,inplace=True)                              # drop all columns with 'Status'\n",
    "df.columns.values[0] = \"Country Name\"                              # change column name by index\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Some pandas functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "## change column name and conditional slicing##\n",
    "###############################################\n",
    "colnames = ['country','year','PPPPC','rule_law','control_corruption','regulatory_quality']\n",
    "df[colnames].head()                                                          # Easy way to get multiple columns from a df\n",
    "df[:3][['country','year','PPPPC']]                                           # retrieve certain rows and columns\n",
    "df.ix[:,0:5]                                                                 # select rows and columns by location\n",
    "df[(df.PPPPC>10000) & (df.rule_law>0)]                                       # retrieve row based on columns values \n",
    "df['year'] = np.arange(df.shape[0])                                          # assing value from 0 to length\n",
    "df.index.values                                                              # values of all row indexes\n",
    "df.columns.values                                                            # show all columns names \n",
    "df.columns =['a','b']                                                        # change columns names directly\n",
    "df.columns.names=['Cities']                                                  # change all columns index name\n",
    "#df = df.rename(columns={'control_corruption':'corruption'})                 # change column name \n",
    "#df.drop(0)                                                                  # drop row\n",
    "#df.drop('regulatory_quality',axis=1)                                        # drop a column, use axis 1 \n",
    "\n",
    "\n",
    "# selecting country data based multiple conditions, and create a copy instead of view\n",
    "USA = df.ix[:,4:6][(df['Country Code']== 111) & (df['Counterpart Country Name'] == 'Japan')].copy()\n",
    "Japan = df.ix[:,4:6][(df['Country Name']== 'Japan') & (df['Counterpart Country Name'] == 'United States')].copy()\n",
    "# for some reason, even with copy, the column names are still linked, so i recreated df using the copyed data\n",
    "df_USA = pd.DataFrame(USA.values,columns=['year','USA_values'])\n",
    "df_Japan = pd.DataFrame(Japan.values,columns=['year','Japan_values'])\n",
    "\n",
    "\n",
    "## select rows based on a list of values \n",
    "keep_country = [111,112,158,146,170,576,532,924]\n",
    "df_test = df_2015[(df_2015.countrycode.isin(keep_country))& df_2015.counterpart_code.isin(keep_country)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "## some statistics ##\n",
    "#####################\n",
    "\n",
    "#create some data\n",
    "df_na = DataFrame([[1,2,3],[np.nan,5,6],[7,np.nan,9],[np.nan,np.nan,np.nan]])\n",
    "\n",
    "df.describe()                                                                # summrize all variables \n",
    "df.PPPPC.cumsum()                                                            # accumulative sum\n",
    "df.min(axis=1)                                                               # row sum, min or others  \n",
    "df_na.dropna()                                                               # drop row when there is na anywhere\n",
    "df_na.dropna(axis=1)                                                         # drop columns with missing data\n",
    "df_na.isnull()                                                               # return boolean list\n",
    "df_na.fillna(0,inplace=True)                                                 # fill na with 0, and change the original df \n",
    "\n",
    "df.sum(level='Temp',axis=1)                                                  # aggregations by group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "########################\n",
    "### minipulatiogn data #\n",
    "########################\n",
    "df = pd.read_csv('data/data.csv',encoding = 'iso-8859-1')\n",
    "\n",
    "df.loc[df.rule_law<0,'rule_law']=0                                         ## recode values, change all negative values to 0\n",
    "df['log_value'] = np.log(df.rule_law)                                      ## create another logged series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##############\n",
    "## merging ###\n",
    "##############\n",
    "\n",
    "#the union of both keys, merge and add addition keys\n",
    "df_merge = pd.merge(df_USA,df_Japan,on='year',how='outer') \n",
    "print(df_merge)\n",
    "\n",
    "####### other merge types ####\n",
    "# pd.merge(df1,df2,on='key')                   #only merged together where keys are in common \n",
    "# pd.merge(df1,df2,on='key',how='left')              #only keep left\n",
    "# pd.merge(df1,df2,on='key',how='right')             #only keep right \n",
    "# pd.merge(df1,df2,on='key',how='outer')             #the union of both keys, merge and add addition keys\n",
    "\n",
    "### merge on multiple columns ####\n",
    "df3 = DataFrame({'key1': ['X', 'y', 'z', 'a', 'b', 'c'],\n",
    "                 'key2':[1,2,3,4,5,6],\n",
    "                 'data_set_3': range(6)})\n",
    "df4 = DataFrame({'key1': ['Y', 'a', 'X', 'b', 'Z'],\n",
    "                 'key2':[2,4,1,3,5],\n",
    "                 'data_set_4': range(5)})\n",
    "\n",
    "pd.merge(df3,df4,on=['key1','key2'],how='left')                          #keep only left, on multiple keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "#### panda df concatenate \n",
    "###########################\n",
    "#similar to stata append \n",
    "df1 = DataFrame(np.random.randn(4,3),columns=['x','y','z'])\n",
    "df2 = DataFrame(np.random.randn(3, 3), columns=['y', 'q', 'x'])\n",
    "pd.concat([df1,df2],ignore_index=True)                   #similar to stata append "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "## combine series into dataframe##\n",
    "##################################\n",
    "\n",
    "## some data\n",
    "country_name = df['Country Name']\n",
    "country_code = df['Country Code']\n",
    "year = df['Time Period']\n",
    "\n",
    "## reading multiple arrays into dataframe\n",
    "df_time =pd.concat([country_name,country_code,year],axis=1) \n",
    "print (df_time.head())\n",
    "\n",
    "## an alternatively way, combining numpy arries into dataframe\n",
    "## but this is significantly slower\n",
    "df_time = pd.DataFrame(np.array([country_name.tolist(),country_code.tolist(),year.tolist()]).T,columns=['name','code','year'])\n",
    "df_time.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Pandas with Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## something "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
